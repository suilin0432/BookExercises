function [] = Exercise8_4(mu, sigma, pointNumber, pointNumberTestList)
% Code for Exercise8_4
% Input Params:
%   mu: μ value
%   sigma: σ value
%   pointNumber: the number of points which we should generate

% In the manual, if we input mean and varianve, then we should use
% following two lines code to calculate mu and sigma

% mu = log((m^2)/sqrt(v+m^2));
% sigma = sqrt(log(v/(m^2)+1));

% set the random seed in order to get the same resulting during the different
% tries.
rng('default');
% generate the data
X = lognrnd(mu,sigma, [1, pointNumber]);
% the true log-normal function
% range: -5~55(cover the min an max value of the generated data) sample: 1:0.05:45
rangeBegin = -5;
rangeEnd = 55;
rangeStep = 0.05;
subplot(2,2,1);
curveX = rangeBegin:rangeStep:rangeEnd;
trueCurve = lognpdf(curveX,mu,sigma);
plot(curveX, trueCurve, 'r');
% perform ksdensity function to get the predict value
[predictY, predictX, bandWidth] = ksdensity(X, curveX);
hold on;
plot(predictX, predictY);
legend("the true pdf", "the pdf predicted by ksdensity");
% As the manual says, " ksdensity estimates the density at 100 points for 
% univariate data, or 900 points for bivariate data." so the bandwith
% actually is the distance between two neighbor points in predictX.

% However in other meaning the bandWidth also means the bandWidth of the
% smooth kernel... So I prefer to use the param returned by ksdensity as
% the bandWidth value.
fprintf("Exercise (b) the bandwidth is %f.\n", bandWidth);

% Exercise(c). set the bandwith before performing the ksdensity function
subplot(2,2,2);
plot(predictX, predictY, 'b');
% set the bandwith to 0.2
hold on;
[predictY, predictX] = ksdensity(X, curveX, 'Bandwidth', 0.2);
plot(predictX, predictY, 'r');
% set the bandwith to 5
hold on;
[predictY, predictX] = ksdensity(X, curveX, 'Bandwidth', 5);
plot(predictX, predictY, 'g');
% plot the other curve to compare them
hold on;
plot(curveX, trueCurve, 'm');
% add lable
legend("auto bandWidth", "bandWidth = 0.2", "bandWidth = 5", "the true curve");

% we could see that as the bandwidth is large, its curve is plan. and when
% the bandwidth is small, it's too sentitive to the sample point that what
% it learns is the feature of the sample datas not the feature of the pdf function

% Exercise(d). change the samples point to find the different bandwidth
% values;
fprintf("\n");
for i = 1:length(pointNumberTestList)
    pointNumber = pointNumberTestList(i);
    X = lognrnd(mu,sigma, [1, pointNumber]);
    [predictY, predictX, bandWidth] = ksdensity(X);
    fprintf("When we have %d points generated by the pdf, we get the bandWidth is %f.\n", pointNumber, bandWidth);
end

% we could see that when the bandwith grows, the bandWidth becomes smaller
% and smaller.

% The result:
% When we have 1000 points generated by the pdf, we get the bandWidth is 0.956515.
% When we have 10000 points generated by the pdf, we get the bandWidth is 0.589579.
% When we have 20000 points generated by the pdf, we get the bandWidth is 0.524218.
% When we have 30000 points generated by the pdf, we get the bandWidth is 0.482563.
% When we have 40000 points generated by the pdf, we get the bandWidth is 0.458100.
% When we have 50000 points generated by the pdf, we get the bandWidth is 0.438018.
% When we have 100000 points generated by the pdf, we get the bandWidth is 0.380033.
% When we have 500000 points generated by the pdf, we get the bandWidth is 0.274657.


